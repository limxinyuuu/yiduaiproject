{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv(\"Trump label project.csv\", header=0, names=['x','text','date','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>linkedin workforce report january february str...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>international women day join honoring critical...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tremendous respect women many roles serve vita...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>feel sure friend come along new great health c...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>let fake news tell big infighting trump admin ...</td>\n",
       "      <td>03/07/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x                                               text        date  label\n",
       "0  0  linkedin workforce report january february str...  03/08/2017      1\n",
       "1  1  international women day join honoring critical...  03/08/2017      0\n",
       "2  2  tremendous respect women many roles serve vita...  03/08/2017      0\n",
       "3  3  feel sure friend come along new great health c...  03/08/2017      0\n",
       "4  4  let fake news tell big infighting trump admin ...  03/07/2017      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=dataframe.drop(\"x\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linkedin workforce report january february str...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>international women day join honoring critical...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tremendous respect women many roles serve vita...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel sure friend come along new great health c...</td>\n",
       "      <td>03/08/2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let fake news tell big infighting trump admin ...</td>\n",
       "      <td>03/07/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        date  label\n",
       "0  linkedin workforce report january february str...  03/08/2017      1\n",
       "1  international women day join honoring critical...  03/08/2017      0\n",
       "2  tremendous respect women many roles serve vita...  03/08/2017      0\n",
       "3  feel sure friend come along new great health c...  03/08/2017      0\n",
       "4  let fake news tell big infighting trump admin ...  03/07/2017      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"from sklearn.utils import shuffle\n",
    "dataframe_s = shuffle(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"max_value=max(dataframe['approval'])\n",
    "min_value=min(dataframe['approval'])\n",
    "one_third=(max_value-min_value)/3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def labeller(value):\n",
    "    if value<=(min_value+one_third):\n",
    "        return 0\n",
    "    elif value>(min_value+one_third) and value<(max_value-one_third):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe['new_label']=dataframe['approval'].apply(labeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataframe.groupby(by='new_label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"for idx, row in dataframe_s.iterrows():\n",
    "    if  dataframe_s.loc[idx,'label'] == -2:\n",
    "        dataframe_s.loc[idx,'new'] = 0\n",
    "    elif  dataframe_s.loc[idx,'label'] == -1:\n",
    "        dataframe_s.loc[idx,'new'] = 0\n",
    "    elif  dataframe_s.loc[idx,'label'] == 0:\n",
    "        dataframe_s.loc[idx,'new'] = 1\n",
    "    elif  dataframe_s.loc[idx,'label'] == 1:\n",
    "        dataframe_s.loc[idx,'new'] = 1\n",
    "    elif  dataframe_s.loc[idx,'label'] == 2:\n",
    "        dataframe_s.loc[idx,'new'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text        date  label\n",
      "0     linkedin workforce report january february str...  03/08/2017      1\n",
      "1     international women day join honoring critical...  03/08/2017      0\n",
      "2     tremendous respect women many roles serve vita...  03/08/2017      0\n",
      "3     feel sure friend come along new great health c...  03/08/2017      0\n",
      "4     let fake news tell big infighting trump admin ...  03/07/2017      1\n",
      "5     working new system competition drug industry p...  03/07/2017      1\n",
      "6     worry getting rid state lines promote competit...  03/07/2017      1\n",
      "7     eight years russia ran president obama got str...  03/07/2017      1\n",
      "8     wonderful new healthcare bill review negotiati...  03/07/2017      1\n",
      "9     vicious prisoners released obama administratio...  03/07/2017      1\n",
      "10    thank billion investment creating manufacturin...  03/07/2017      0\n",
      "11    buy american hire american principles core age...  03/07/2017      0\n",
      "12    incredible spirit optimism sweeping country ri...  03/06/2017      0\n",
      "13    construction manufacturing jobs u gulf coast r...  03/06/2017      0\n",
      "14    buy american hire american principals core age...  03/06/2017      0\n",
      "15    president trump congratulates exxon mobil job ...  03/06/2017      0\n",
      "16    thank great rallies across country tremendous ...  03/05/2017      0\n",
      "17    secretly said russian president tell vladimir ...  03/05/2017      1\n",
      "18    true dnc would allow fbi access check server e...  03/05/2017      1\n",
      "19    arnold schwarzenegger voluntarily leaving appr...  03/04/2017      1\n",
      "20    low president obama gone tapp phones sacred el...  03/04/2017      1\n",
      "21    bet good lawyer could make great case fact pre...  03/04/2017      1\n",
      "22    legal sitting president wire tapping race pres...  03/04/2017      1\n",
      "23    russian ambassador met jeff sessions visited o...  03/04/2017      1\n",
      "24    terrible found obama wires tapped trump tower ...  03/04/2017      1\n",
      "25    first meeting jeff sessions russian amb set ob...  03/04/2017      1\n",
      "26                                   make america great  03/03/2017      0\n",
      "27    hereby demand second investigation schumer pel...  03/03/2017      0\n",
      "28    hearby demand second investigation schumer pel...  03/03/2017      0\n",
      "29    must fix education system kids make america gr...  03/03/2017      0\n",
      "...                                                 ...         ...    ...\n",
      "4305  arrived mississippi rally word crowd overflowi...  01/03/2016      1\n",
      "4306  heading biloxi mississippi massive crowds expe...  01/02/2016      0\n",
      "4307  remember self funding campaign one either part...  01/02/2016      1\n",
      "4308  look money special interests lobbyists giving ...  01/02/2016      1\n",
      "4309  hope bill clinton starts talking women issues ...  01/02/2016      1\n",
      "4310  hillary clinton strength stamina president jeb...  01/02/2016      1\n",
      "4311  hillary clinton said k ban muslims israel buil...  01/02/2016      1\n",
      "4312  low energy stiff focus special interest money ...  01/02/2016      1\n",
      "4313  sad case total embarrassment family announced ...  01/02/2016      1\n",
      "4314  massive crowds expected mississippi tomorrow n...  01/02/2016      0\n",
      "4315  votetrump together makeamericagreatagain thank...  01/02/2016      0\n",
      "4316      thank much naming man year indeed great honor  01/02/2016      1\n",
      "4317  person hillary clinton least wants run far lar...  01/01/2016      1\n",
      "4318  never interested politics want get political s...  01/01/2016      1\n",
      "4319  going mississippi tomorrow night hear crowds g...  01/01/2016      1\n",
      "4320           huckabee good man needs get behind agree  01/01/2016      1\n",
      "4321  one biggest fans mr trump wait make america gr...  01/01/2016      1\n",
      "4322  standing spreading word trump president wake s...  01/01/2016      1\n",
      "4323                      love u trump family god bless  01/01/2016      1\n",
      "4324  well year officially begun many stops planned ...  01/01/2016      1\n",
      "4325  spending millions still going win go donald trump  01/01/2016      1\n",
      "4326  hillary said fog war explanation lies benghazi...  01/01/2016      1\n",
      "4327  happy new year maralago thank great family sup...  01/01/2016      0\n",
      "4328                                happynewyearamerica  01/01/2016      0\n",
      "4329                               happy new year thank  01/01/2016      0\n",
      "4330  live members family p ring new year together m...  01/01/2016      1\n",
      "4331  would like wish everyone happy healthy new yea...  12/31/2015      1\n",
      "4332  believe state department new year eve released...  12/31/2015      1\n",
      "4333  thank illinois let forget get family friends vote  12/31/2015      0\n",
      "4334                       happy birthday son proud tbt  12/31/2015      0\n",
      "\n",
      "[4335 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(dataframe, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>thank maryland trump</td>\n",
       "      <td>04/27/2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>join oklahoma tomorrow night makeyoutubegreata...</td>\n",
       "      <td>02/25/2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>limited edition signed copies book art deal do...</td>\n",
       "      <td>08/06/2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>one biggest fans mr trump wait make america gr...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>hillary clinton points ahead debatenight</td>\n",
       "      <td>09/27/2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        date  label\n",
       "2785                               thank maryland trump  04/27/2016      0\n",
       "3507  join oklahoma tomorrow night makeyoutubegreata...  02/25/2016      0\n",
       "1672  limited edition signed copies book art deal do...  08/06/2016      0\n",
       "4321  one biggest fans mr trump wait make america gr...  01/01/2016      1\n",
       "1260           hillary clinton points ahead debatenight  09/27/2016      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (df.shape) #Take the first number from X_data.shape and store it in num_of_rows\n",
    "num_of_rows = int((df.shape[0]) * 0.8)\n",
    "\n",
    "train_data = df.iloc[:num_of_rows] #indexes rows for training data\n",
    "test_data = df.iloc[num_of_rows:] #indexes rows for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=train.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['label']=train['label']+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test=test.dropna()\n",
    "#test['label']=test['label']+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(train_data, train_data['label'], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(train_data, train_data[\"label\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(test_data, test_data[\"label\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_input_fn=tf.estimator.inputs.pandas_input_fn(train_data, train_data['label'],num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_input_fn=tf.estimator.inputs.pandas_input_fn(test_data, test_data['label'],num_epochs=1000, shuffle=True)\n",
    "#predict_train_input_fn=tf.estimator.inputs.pandas_input_fn(train, train['new_label'],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_test_input_fn=tf.estimator.inputs.pandas_input_fn(test_data,test_data['label'],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config=tf.estimator.RunConfig(keep_checkpoint_max=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using C:\\Users\\Admin\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "embedded_text_feature_column=hub.text_embedding_column(key='text',module_spec='https://tfhub.dev/google/nnlm-en-dim128/1',trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Temp\\\\tmpe24jhwlq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000196318FFF28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator=tf.estimator.DNNClassifier(\n",
    "    hidden_units=[200,50,50],\n",
    "    feature_columns=[embedded_text_feature_column],\n",
    "    n_classes=2,\n",
    "    config=run_config,\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt.\n",
      "INFO:tensorflow:loss = 88.710526, step = 0\n",
      "INFO:tensorflow:global_step/sec: 148.232\n",
      "INFO:tensorflow:loss = 83.97154, step = 100 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.902\n",
      "INFO:tensorflow:loss = 81.225586, step = 200 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.953\n",
      "INFO:tensorflow:loss = 75.0348, step = 300 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.095\n",
      "INFO:tensorflow:loss = 71.90546, step = 400 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.721\n",
      "INFO:tensorflow:loss = 69.20944, step = 500 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.159\n",
      "INFO:tensorflow:loss = 63.675373, step = 600 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.094\n",
      "INFO:tensorflow:loss = 66.90625, step = 700 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.841\n",
      "INFO:tensorflow:loss = 63.55078, step = 800 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.579\n",
      "INFO:tensorflow:loss = 57.114754, step = 900 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.467\n",
      "INFO:tensorflow:loss = 58.192448, step = 1000 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.183\n",
      "INFO:tensorflow:loss = 54.466705, step = 1100 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.116\n",
      "INFO:tensorflow:loss = 52.839325, step = 1200 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.256\n",
      "INFO:tensorflow:loss = 41.716644, step = 1300 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.676\n",
      "INFO:tensorflow:loss = 37.3378, step = 1400 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.481\n",
      "INFO:tensorflow:loss = 48.481598, step = 1500 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.577\n",
      "INFO:tensorflow:loss = 44.075443, step = 1600 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.257\n",
      "INFO:tensorflow:loss = 52.5777, step = 1700 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.135\n",
      "INFO:tensorflow:loss = 42.297558, step = 1800 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.877\n",
      "INFO:tensorflow:loss = 44.107864, step = 1900 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.116\n",
      "INFO:tensorflow:loss = 43.241608, step = 2000 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.723\n",
      "INFO:tensorflow:loss = 35.690556, step = 2100 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.523\n",
      "INFO:tensorflow:loss = 41.001488, step = 2200 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.77\n",
      "INFO:tensorflow:loss = 42.975067, step = 2300 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.917\n",
      "INFO:tensorflow:loss = 29.802586, step = 2400 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.447\n",
      "INFO:tensorflow:loss = 29.271202, step = 2500 (0.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.867\n",
      "INFO:tensorflow:loss = 32.130608, step = 2600 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.489\n",
      "INFO:tensorflow:loss = 36.714493, step = 2700 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.362\n",
      "INFO:tensorflow:loss = 28.555069, step = 2800 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.9\n",
      "INFO:tensorflow:loss = 23.541424, step = 2900 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.036\n",
      "INFO:tensorflow:loss = 29.442886, step = 3000 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.024\n",
      "INFO:tensorflow:loss = 30.800562, step = 3100 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.503\n",
      "INFO:tensorflow:loss = 22.695711, step = 3200 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.64\n",
      "INFO:tensorflow:loss = 34.035885, step = 3300 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.477\n",
      "INFO:tensorflow:loss = 28.104715, step = 3400 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.909\n",
      "INFO:tensorflow:loss = 16.031376, step = 3500 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.631\n",
      "INFO:tensorflow:loss = 24.463308, step = 3600 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.056\n",
      "INFO:tensorflow:loss = 19.201458, step = 3700 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.969\n",
      "INFO:tensorflow:loss = 19.752922, step = 3800 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.577\n",
      "INFO:tensorflow:loss = 17.289494, step = 3900 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.202\n",
      "INFO:tensorflow:loss = 25.276373, step = 4000 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.525\n",
      "INFO:tensorflow:loss = 18.169914, step = 4100 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.026\n",
      "INFO:tensorflow:loss = 16.006666, step = 4200 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.835\n",
      "INFO:tensorflow:loss = 20.12025, step = 4300 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.919\n",
      "INFO:tensorflow:loss = 17.103876, step = 4400 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.813\n",
      "INFO:tensorflow:loss = 14.826144, step = 4500 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.058\n",
      "INFO:tensorflow:loss = 15.634101, step = 4600 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.318\n",
      "INFO:tensorflow:loss = 17.20604, step = 4700 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.371\n",
      "INFO:tensorflow:loss = 17.83483, step = 4800 (0.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.767\n",
      "INFO:tensorflow:loss = 11.730621, step = 4900 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.823\n",
      "INFO:tensorflow:loss = 15.89942, step = 5000 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.674\n",
      "INFO:tensorflow:loss = 15.194702, step = 5100 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.391\n",
      "INFO:tensorflow:loss = 11.420586, step = 5200 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.328\n",
      "INFO:tensorflow:loss = 17.51463, step = 5300 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.331\n",
      "INFO:tensorflow:loss = 13.516276, step = 5400 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.512\n",
      "INFO:tensorflow:loss = 10.504721, step = 5500 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.376\n",
      "INFO:tensorflow:loss = 15.917154, step = 5600 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.823\n",
      "INFO:tensorflow:loss = 16.317211, step = 5700 (0.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.495\n",
      "INFO:tensorflow:loss = 12.797114, step = 5800 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.933\n",
      "INFO:tensorflow:loss = 12.752796, step = 5900 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.109\n",
      "INFO:tensorflow:loss = 10.302963, step = 6000 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.5\n",
      "INFO:tensorflow:loss = 10.058776, step = 6100 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.461\n",
      "INFO:tensorflow:loss = 13.403047, step = 6200 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.788\n",
      "INFO:tensorflow:loss = 14.696503, step = 6300 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.827\n",
      "INFO:tensorflow:loss = 6.0767612, step = 6400 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.985\n",
      "INFO:tensorflow:loss = 13.045404, step = 6500 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.922\n",
      "INFO:tensorflow:loss = 11.589773, step = 6600 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.013\n",
      "INFO:tensorflow:loss = 8.6929, step = 6700 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.641\n",
      "INFO:tensorflow:loss = 11.42878, step = 6800 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.399\n",
      "INFO:tensorflow:loss = 7.9485407, step = 6900 (0.608 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.985138.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x196318e7e48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn,steps=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-15:54:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-15:54:27\n",
      "INFO:tensorflow:Saving dict for global step 7000: accuracy = 0.98440206, accuracy_baseline = 0.5418833, auc = 0.99764025, auc_precision_recall = 0.9976198, average_loss = 0.06640708, global_step = 7000, label/mean = 0.4581167, loss = 8.210761, precision = 0.98358583, prediction/mean = 0.4584361, recall = 0.9823455\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt-7000\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.984402060508728\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: {accuracy}\".format(**train_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-15:54:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-15:54:36\n",
      "INFO:tensorflow:Saving dict for global step 7000: accuracy = 0.7739331, accuracy_baseline = 0.51557094, auc = 0.85065246, auc_precision_recall = 0.8362243, average_loss = 0.6666684, global_step = 7000, label/mean = 0.48442906, loss = 82.57165, precision = 0.7758621, prediction/mean = 0.46101257, recall = 0.75\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt-7000\n"
     ]
    }
   ],
   "source": [
    "test_eval_result=estimator.evaluate(input_fn=predict_test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Training Accuracy: 0.7739331126213074\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Training Accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEKCAYAAADU7nSHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHAdJREFUeJzt3XucVWXd9/HPdwbM8zkOAhImZmKJaFiZ5SFP3aZipYjko97Gk0mWPFlqpaWWZlpPdpO3aFZWHkt7UAlSi8ryABqlTCoHDwxnkeSWOM2e3/PHXsBmmMOeYa+912K+b1/rxV57X3NdFzr+5je/da1rKSIwM7Nsq6v1BMzMrGMO1mZmOeBgbWaWAw7WZmY54GBtZpYDDtZmZjngYG1mlgMO1mZmOeBgbWaWAz1qPYG2rHt9rm+ttM1st9cRtZ6CZVDT2vna0j46E3N67rnPFo/XWc6szcxyILOZtZlZVTUXaj2DdjlYm5kBFJpqPYN2OVibmQERzbWeQrscrM3MAJodrM3Mss+ZtZlZDvgCo5lZDjizNjPLvvBqEDOzHPAFRjOzHHAZxMwsB3yB0cwsB5xZm5nlgC8wmpnlgC8wmpllX4Rr1mZm2eeatZlZDrgMYmaWA86szcxyoLCu1jNol4O1mRm4DGJmlgsug5iZ5YAzazOzHHCwNjPLvvAFRjOzHHDN2swsB1wGMTPLAWfWZmY54MzazCwHnFmbmeVAU7YfPlBX6wmYmWVCNJd/dEDSCZJelDRb0qWtfP59STOS4yVJ/+qoT2fWZmZQsZq1pHpgPHAs0AhMkzQxIhrWt4mIi0vafx44uKN+nVmbmUElM+vhwOyImBsRa4G7gVPaaX8mcFdHnTqzNjODSq4G6QfMKzlvBA5rraGkgcAg4PcdderM2swMOpVZSxojaXrJMaakJ7XWexujjgR+FWU8ANKZtZkZdGo1SERMACa08XEjMKDkvD+woI22I4ELyxnTmbWZGUBE+Uf7pgGDJQ2StA3FgDyxZSNJ7wJ2A54oZ3rOrM3MoGI164hokjQWmALUA7dHxExJVwHTI2J94D4TuDui4+gPDtZmZkUVvN08IiYBk1q8d0WL8290pk8HazMz8O3mZma5UOhwQUZNOVibmYF33TMzywUHazOzHHDN2sws+6K5rBV0NeNgbWYGLoOYmeWCV4OYmeVAxjNr7w2SIY8/OZ2TRp7Piaefx20/v3ezzxcuWsK5Y7/CJ8+5kBFnX8Cf/vp0DWZp1Xb8cUcy8/k/8ULD43z5ks33/PniF8bwj7//gWefeYTfTb6HvffuV4NZbgWam8s/asDBOiMKhQLX3Diem2+8mom/vIVJj05lzsuvbtLmlp/dxfHHHMGvfjqeG755KdfcOL5Gs7Vqqaur46YffIuTPj6a9xx0FGeccSrvfvfgTdrMmPE8h73/RIYdciy/vv9hrrv2azWabc5VbiOnVDhYZ8Rz/3yJvfvvxYB+fenZsycnHvMRfv/nJzdpI4mVK/8NwP+s/Ddv33OPWkzVqmj4+w5mzpxXePnl11i3bh333vv/OPnjx2/SZuof/8qqVasBeOrpZ+jfr28tppp/Gc+sXbPOiCVLX6dPr7dvOO/da0+em/niJm0+d95oxlz8Ve781URWrV7Drf/329WeplXZXv36MK9x41bIjfMXMvx9bT+u79xzzmTylD9UY2pbn4wv3Us1s5Z0vaSdJfWU9Jik1yWNTnPMvGrtNyu1eN7EpEencsrHPspjv/kFP7rhKi67+rs0Z/yiiG0ZtfwmANraUXPUqNM49JCDuOHGm9Oe1tapUCj/qIG0yyDHRcQK4CSKT0/YD7ikrcalj8q57Y4Onx+5Venda08WLVm64Xzxktc3K3Pc/+AUjj/6wwAMPfDdrF27juVvrqjqPK265jcuZED/vTac9+/Xl4ULF2/W7pijj+CySy/i1NPOYe3atdWc4lYjmpvLPmoh7WDdM/nzY8BdEfFGe40jYkJEHBoRh55/9pkpTy1bDtx/P15rXEDjgkWsW7eO3z72R4760Ps3adO3Ty+emj4DgDmvvMaaNWvZfdddajFdq5Jp02ew776DeMc7BtCzZ09OP/0UHnzod5u0GTp0CD8afx0jTjuXpUuX1WimW4HmKP+ogbRr1hMlvQCsAj4n6e3A6pTHzKUePeq5/OIL+N/jvkahUGDEScex7z4D+a9b72DI/vtx1BHv55Kx53Pld27ijnsfQIhrvjqu1V+TbetRKBT4whe/xqSH76S+ro6f/uweGhpe4htXfonpz/ydhx56hO9c+3V23HEH7r7rFgDmzZvPiNPOrfHMcyjje4OozCfKdL5jqQ54P/BPYEVEFCTtAOwUEYs6+vp1r8/NdrXfamK7vY6o9RQsg5rWzt/irGXlVWeVHXN2uOKXVc+SUsusI6JZ0o0R8YGS91YCK9Ma08ysy5qyfbt52jXr30n6hPy7upllXTSXf9RA2jXrccAOQEHSKkBARMTOKY9rZtY5GV9nnWqwjoid0uzfzKxSarUkr1xp3xQjSaMlfT05HyBpeJpjmpl1ScaX7qVds/4R8AFgVHL+FuDdh8wsezIerNOuWR8WEcMk/Q0gIpZL2iblMc3MOq+bP3xgnaR6IACSm2KyXRgys26puz+D8SbgAaCXpG8BnwS82a6ZZU93DtYR8UtJzwDHUFy2d2pE/DPNMc3MuqQ7rwZJzKKYXU8EVkrauwpjmpl1TgUvMEo6QdKLkmZLurSNNqdLapA0U9KdHfWZamYt6fPAlcBioEByUwzw3jTHNTPrtAqVQZLrdOOBYyluDT1N0sSIaChpMxi4DDg8WXjRq6N+065ZfwF4V0R430Yzy7QoVKwMMhyYHRFzASTdDZwCNJS0+QwwPiKWA0TEko46TbsMMg94M+UxzMy2XCfKIKUPSkmOMSU99aMY+9ZrTN4rtR+wn6S/SHpS0gkdTS+VzFrSuOTlXGCqpIeBNes/j4jvpTGumVlXdWbpXkRMACa08XFrG9e17LwHMBg4EugP/FnSgRHxr7bGTKsMsn5PkNeSY5vkgM0nbWZWe5VbutcIDCg57w8saKXNkxGxDnhZ0osUg/e0tjpNJVhHxDcBJH0qIu4r/UzSp9IY08xsi1Ru5d40YLCkQcB8YCQbt9xY7zfAmcBPJe1JsSwyt71O065ZX1bme2ZmNRVNzWUf7fYT0QSMBaZQfFLWvRExU9JVkk5Omk0BlklqAP4AXNLRQoy0atYnUnxIbj9JN5V8tDPQlMaYZmZbpIL3xETEJGBSi/euKHkdFPf7H0eZ0qpZLwCmA58CXqJYpy5QXG99cUpjmpl1WXfdG6QBOIviRcXzKF4dHQD8BHgopTHNzLou23ebp1azvh7YDRgYEcMi4mBgH2AX4IaUxjQz67JojrKPWkgrsz4J2C+pywAQESskXQC8QPHORjOz7Mh4Zp1WsI7SQF3yZkFStgtDZtYtRcaXPqRVBmmQdHbLNyWNpphZm5llSjSXf9RCWpn1hcD9ks4DnqG4GuR9wHbAiJTGNDPruu5YBomI+cBhko4GhlBcDfLbiHgsjfHMzLZUrTLmcqX9pJjfA79Pcwwzs0ro1sHazCwvotDaZnnZ4WBtZoYzazOzXIhmZ9ZmZpnnzNrMLAcinFmbmWWeM2szsxxo9moQM7Ps8wVGM7MccLA2M8uBzfcJzRYHazMznFmbmeXCVrN0T9LbImJNmpMxM6uVQsZXg3T48AFJwyU9B8xKzg+S9MPUZ2ZmVkURKvuohXKeFHMTxWcqLgOIiL8DR6U5KTOzaotmlX3UQjllkLqIeFXaZIKFlOZjZlYTW8NqkHmShgMhqR74PPBSutMyM6uurWE1yAUUSyF7A4uBR5P3zMy2GoXmtJ4fXhkdzi4ilkTEyIjYMzlGRsTr1ZicmVm1RJR/dETSCZJelDRb0qWtfH6OpKWSZiTH+R312WFmLelWik8nb/EXizEdT9nMLB+aK7TKIykXjweOBRqBaZImRkRDi6b3RMTYcvstpwzyaMnrbYERwLxyBzAzy4MKLskbDsyOiLkAku4GTgFaButO6TBYR8Q9peeSfg48siWDmpllTQVXg/Rj04S2ETislXafkPRhigs2Lo6IdpPgrtxuPggY2IWv65R933Vq2kNYDr315M21noJtpTpTBpE0BigtBU+IiAnrP27lS1r+KHgQuCsi1kj6LPAz4Oj2xiynZr28ZKA64A1gs4K5mVmedWY1SBKYJ7TxcSMwoOS8P7CgxdcvKzm9FfhOR2O2G6xVvBPmIGB+8lZzRNaXjpuZdV4FA9s0YLCkQRRj50hgVGkDSX0jYmFyejLwz446bTdYR0RIeiAiDunanM3M8qFSq0EioknSWGAKUA/cHhEzJV0FTI+IicBFkk4GmihWK87pqN9yatZPSxoWEc92ffpmZtlWyQ2aImISMKnFe1eUvL4MuKwzfbYZrCX1iIgm4EPAZyTNAVZSLJ5HRAzrzEBmZlmW8Yebt5tZPw0MA7wsw8y2etHqIo7saC9YCyAi5lRpLmZmNdOU4yfFvF3SuLY+jIjvpTAfM7OayHNmXQ/sSOsLvM3Mtip5rlkvjIirqjYTM7MaynNmne2Zm5lVUJ4z62OqNgszsxorZDw/bTNYR8Qb1ZyImVktZfypXl3adc/MbKvTnNfM2sysO8n6DnUO1mZm5PsCo5lZt9Esl0HMzDKvUOsJdMDB2swMrwYxM8sFrwYxM8sBrwYxM8sBl0HMzHLAS/fMzHKg4MzazCz7nFmbmeWAg7WZWQ5k/BGMDtZmZuDM2swsF3y7uZlZDnidtZlZDrgMYmaWA1kP1nW1noCZWRZEJ46OSDpB0ouSZku6tJ12n5QUkg7tqE9n1mZmVK5mLakeGA8cCzQC0yRNjIiGFu12Ai4CniqnX2fWZmYUV4OUe3RgODA7IuZGxFrgbuCUVtpdDVwPrC5nfg7WZmZAM1H20YF+wLyS88bkvQ0kHQwMiIiHyp2fg7WZGcULjOUeksZIml5yjCnpqrWCyoYIL6kO+D7wfzozP9eszczo3MMHImICMKGNjxuBASXn/YEFJec7AQcCU1V8SG8fYKKkkyNieltjOlibmVHRpXvTgMGSBgHzgZHAqPUfRsSbwJ7rzyVNBb7UXqAGB2szMwCaVJkHe0VEk6SxwBSgHrg9ImZKugqYHhETu9Kvg7WZGZV9BmNETAImtXjvijbaHllOnw7WZmZk/w5GB2szMyhnSV5NOVibmVHZMkgaHKzNzHAZxMwsFwoZz60drM3McGZtZpYL4czazCz7nFlbuz5y9OFcee1XqK+r4+5f3M/NP7h9k8/Pv+DTjPz0aTQ1FXhj2XIu+fwVzG9cCMDcJX/jhYZZACxoXMT5oy+q+vwtHX+Z8QLfuWMizc3NjDhqOP95ytGbfP7dOyYyrWE2AKvWrGP5ird4/MdXA3DwqC8zeO8+APTZYzduuuTc6k4+p7x0z9pUV1fH1ddfzlmfGMOiBYuZ+OhdPDp5KrNenLuhzcznXuCkY85k9arVjD73dC77xsWMPf/LAKxetYaPHXl6raZvKSk0N/PtnzzALZePofceuzDqqzdx5CFDeGf/3hvaXHL2yRte3zn5cV54ZeM+QW/bpif3XjeuqnPeGmQ7VKe4Raqk3SR9X9LTkp6SdKOk3dIaL4+GDjuQV15+jXmvzmfduiYefGAyx5541CZtnnh8GqtXFfcm/9v0f9B3r96tdWVbkednv8aAPnvSv/ce9OzRgxM+MJSp02e22X7yX2dw4geHVnGGW6cmouyjFtLcz/puYAVwFjA6eX1PiuPlTp++vVk4f/GG84ULFtOnb682258xegRTH3t8w/nbtt2GBx+7iwem/ILjPnZUm19n+bJk+Qr67LHrhvNee+zC4uVvttp2wdLlzF/6BsMP3HfDe2vXNXHm5T9g9Nd/yO+nPZ/6fLcW0Yl/aiHNMsieEXFlyfk3JT3T3hckG3iPAdh9+37suO3uKU4vA1rZojyi9W+EEZ/6D94zdAhnfHxj/fEDBx3PkkVLGTCwH3f95jZeaJjFa680pjVbq5LWvgfU6n72MPmJGXx0+Hupr9uYd03+4eX02n0XGhcv4zPX3MLgvfswoPeerX69bZT1C4xpZtZ/lPTJ9SeSTgN+294XRMSEiDg0Ig7d6gM1sGjBYvr221jW6LtXbxYvWrpZu8M/chhjx32G88+6iLVr1214f0nSdt6r83nyL9M58D3vTn/Slrreu+/ComX/2nC+ZNmb9Npt51bbTv7rDE48fNMSSK/ddwGgf+89OPSAfTapZ1vbsp5ZpxmszwXulbRG0hrgV8CFkpZLeiPFcXPj73+byaB9BjJg73707NmDj484gUd+O3WTNkPesz/X3ngF/3nWRSx7feO/tp132YlttukJwG6778qhw4cy66U51Zy+pWTIOwfw2qLXaVzyBuuampj8xAw+csgBm7V7ZcES/mflKg4aPHDDeyve+jdr1zUBsHzFSma89Cr79PN1jnJ05rFetZBqGSTFvrcKhUKBK77ybe6472bq6+u5987fMOvFOYy79HP8Y0YDj06eyuXfHMf2O2zPj26/Adi4RG/wfvvw7e9dQXNzM3V1ddz8g9s3WUVi+dWjvp7LzjmVC669lebmZk49cjj7DujD+PumMGRQf448dAgAv/3rDI7/4FCSR0MBMHfBEq6+7dfUSTRHcO7JR22yisTaVmijBJkVaqtGWpHOpQOAd1DyQ6HcpyQM3OO92f43ZzXx4iPX1HoKlkHbDju59aJ+J4waOKLsmHPnqw9s8XidlVpmLelW4FCggY2/OQTQpUfamJmlqTvfbv4h4IBIM3U3M6uQ7rwa5ClgvxT7NzOrmGai7KMW0sysfww8JWk+sIbiquKIiGEpjmlm1iXduQxyO3Ae8BzZ/w3DzLq5rK8GSTNYz4uI+1Ps38ysYrrzrnsNku4AHqRYBgHKX7pnZlZNWf/1P81gvUvy58kl73npnpllUretWUfEp9Pq28ys0rptGUTShNbej4gxaY1pZtZVWb8lJM0yyGMlr7cFRgDzUhzPzKzLCt01s46ITR40IOnnwCNpjWdmtiUqWQaRdALwA6AeuC0irmvx+WeBC4EC8BYwJiIa2uszzTsYWxoEDOywlZlZDURE2Ud7JNUD44ETgQOAM5NN7UrdGRHviYihwPXA9zqaX5o16+VsfAZlHfAGcGla45mZbYkKZtbDgdkRMRdA0t3AKRQ3tQMgIlaUtN+BMp7Xm0qwVnGD3YOA+clbzd7QycyyrDNL90ofQZiYEBHrF1X0Y9Prc43AYa30cSEwDtgGOLqjMVMJ1hERkh6IiEPS6N/MrNI6c7t5EphbXfFGq09X3fwnQUSMB8ZLGgV8Dfhf7Y2ZZs36aUnetMnMcqGCu+41AgNKzvsD7T0I827g1I46rXhmLalHRDRR3M/6M5LmACvxrntmlmEVrFlPAwZLGkSxFDwSGFXaQNLgiJiVnP4HMIsOpFEGeRoYRhk/KczMsqJSl9UioknSWGAKxaV7t0fETElXAdOT/ZHGSvoosA5YTgclEEgnWCuZsB+1bWa5Ucl11hExCZjU4r0rSl5/obN9phGs3y5pXFsfRkSH6wnNzKqtO27kVA/sSOtXRM3MMqkQ2d4kNY1gvTAirkqhXzOz1GT9VpDUatZmZnnSHbdIPSaFPs3MUtXtatYR8Ual+zQzS1tzNyyDmJnlTrfLrM3M8qg7rgYxM8sdl0HMzHLAZRAzsxxwZm1mlgPOrM3McqAQhVpPoV0O1mZmdM/bzc3Mcqc73m5uZpY7zqzNzHLAq0HMzHLAq0HMzHLAt5ubmeWAa9ZmZjngmrWZWQ44szYzywGvszYzywFn1mZmOeDVIGZmOeALjGZmOeAyiJlZDvgORjOzHHBmbWaWA1mvWSvrP00MJI2JiAm1nodli78vupe6Wk/AyjKm1hOwTPL3RTfiYG1mlgMO1mZmOeBgnQ+uS1pr/H3RjfgCo5lZDjizNjPLAa+zrhJJ/YHxwAEUf0g+BFySnO8VEZOSdt8A3oqIG2o0VasSSXsAjyWnfYACsDQ5Hx4Ra2syMcskZ9ZVIEnA/cBvImIwsB+wI/AtYCjwsQqOVV+pvixdEbEsIoZGxFDgv4Hvrz9fH6hV5P9PzcG6So4GVkfETwAiogBcDJwPXA+cIWmGpDOS9gdImipprqSL1nciabSkp5O2t6wPzJLeknSVpKeAD0i6TlKDpH9IcoaeM5L2lfS8pP8GngUGSPpXyecjJd2WvP6FpPGS/iBpjqQPS/qZpBck/Thp00PSvyR9X9Kzkh5JsnrLEQfr6hgCPFP6RkSsAF4BrgHuSbKpe5KP9weOB4YDV0rqKendwBnA4UkmVgDOStrvADwfEYcBDcAIYEhEvDfp3/LnAODHEXEwML+DtrtExFHAl4EHge8kX3+IpAPXtwGejIhhwBPA19OZtqXFNevqELS6pVdb7z8cEWuANZKWAL2BY4BDgGnFqgrbAUuS9gXg18nrFcBq4DZJD1OsjVv+zImIaWW2fTD58zlgQUQ0AEhqAN4BvAA0Afcl7X4B3Fm5qVo1OFhXx0zgE6VvSNoZGEAx0La0puR1geJ/JwE/i4jLWmm/OimtEBFNkoZTDO4jgbEUyzCWLytLXjdT/O+/3rYt2q4paVf6vdPMxv/HWyYFXrObMy6DVMdjwPaSzoYNFwFvBH4KLAZ2KrOPT0rqlfSxu6SBLRtJ2pHir8WTgC9SvIBpORYRzcBySYOTi40jutBNT+C05PUo4PFKzc+qw8G6CqJ459EI4FOSZgEvUSxVXA78geIFxdILjK310QB8DfidpH8AjwB9W2m6E/BQ0uaPFC9kWv59BZhM8Yd2Yxe+/k1gmKRngQ/haxm54zsYzbZyknoAr0fErrWei3WdM2szsxxwZm1mlgPOrM3McsDB2swsBxyszcxywMHaKk5SIVmK+Lyk+yRtvwV9HSnpoeT1yZIubaftrpI+14UxviHpS12do1k1OFhbGlYle50cCKwFPlv6YVd3kouIiRFxXTtNdgU6HazN8sDB2tL2Z2BfSe+Q9E9JP2LjTnLHSXoi2QnuvuTuSySdkOwa9zgb77pD0jmS/it53VvSA5L+nhwfBK4D3plk9d9N2l0iaVqyA+E3S/r6qqQXJT0KvKtq/zbMusjB2lKT3IxxIsUNhqAYFO9IdpJbSfGOzI8mO8FNB8ZJ2ha4Ffg4cATFTflbcxPwx4g4CBhGcf+VSylugDQ0Ii6RdBwwmOLuhUMp7kL3YUmHUNw35WCKPwzeV+G/ulnFeSMnS8N2kmYkr/8M/BjYC3g1Ip5M3n8/xW08/5LsIrgNxa079wdejohZUNyvGRjTyhhHA2fDhv3B35S0W4s2xyXH35LzHSkG752AByLi38kYE7fob2tWBQ7WloZVyZ7bGyQBuXQnOQGPRMSZLdoNpXI7wgm4NiJuaTHGFys4hllVuAxitfIkcLikfQEkbS9pP4p7Lw+S9M6k3ZltfP1jwAXJ19YnW87+D5vuYDgFOK+kFt4v2bXwT8AISdtJ2oliycUs0xysrSYiYilwDnBXskPgk8D+EbGaYtnj4eQC46ttdPEF4ChJz1F8Cs+QiFhGsazyvKTvRsTvKG6y/0TS7lfAThHxLHAPMIPiQxv+nNpf1KxCvDeImVkOOLM2M8sBB2szsxxwsDYzywEHazOzHHCwNjPLAQdrM7MccLA2M8sBB2szsxz4/0USeWFMmx9gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "  return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "with tf.Graph().as_default():\n",
    "  cm = tf.confusion_matrix(test_data[\"label\"],\n",
    "                           get_predictions(estimator, predict_test_input_fn))\n",
    "  with tf.Session() as session:\n",
    "    cm_out = session.run(cm)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm_out = cm_out.astype(float) / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_out,\n",
    "    annot=True,\n",
    "    xticklabels=['Others','Trump'],\n",
    "    yticklabels=['Others','Trump'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets=pd.read_csv('C://Users//Admin//Yidu AI//Predict Data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates=pd.DataFrame()\n",
    "Dates=new_tweets['Date']\n",
    "new_tweets.drop(['Unnamed: 0', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11/30/2018\n",
       "1      11/30/2018\n",
       "2      11/30/2018\n",
       "3      11/30/2018\n",
       "4      11/30/2018\n",
       "5      11/30/2018\n",
       "6      11/30/2018\n",
       "7      11/30/2018\n",
       "8      11/30/2018\n",
       "9      11/29/2018\n",
       "10     11/29/2018\n",
       "11     11/29/2018\n",
       "12     11/29/2018\n",
       "13     11/29/2018\n",
       "14     11/29/2018\n",
       "15     11/29/2018\n",
       "16     11/29/2018\n",
       "17     11/29/2018\n",
       "18     11/29/2018\n",
       "19     11/29/2018\n",
       "20     11/29/2018\n",
       "21     11/29/2018\n",
       "22     11/29/2018\n",
       "23     11/28/2018\n",
       "24     11/28/2018\n",
       "25     11/28/2018\n",
       "26     11/28/2018\n",
       "27     11/28/2018\n",
       "28     11/28/2018\n",
       "29     11/28/2018\n",
       "          ...    \n",
       "571    10/03/2018\n",
       "572    10/03/2018\n",
       "573    10/03/2018\n",
       "574    10/03/2018\n",
       "575    10/03/2018\n",
       "576    10/03/2018\n",
       "577    10/03/2018\n",
       "578    10/03/2018\n",
       "579    10/03/2018\n",
       "580    10/03/2018\n",
       "581    10/03/2018\n",
       "582    10/03/2018\n",
       "583    10/02/2018\n",
       "584    10/02/2018\n",
       "585    10/02/2018\n",
       "586    10/02/2018\n",
       "587    10/02/2018\n",
       "588    10/02/2018\n",
       "589    10/02/2018\n",
       "590    10/02/2018\n",
       "591    10/02/2018\n",
       "592    10/02/2018\n",
       "593    10/01/2018\n",
       "594    10/01/2018\n",
       "595    10/01/2018\n",
       "596    10/01/2018\n",
       "597    10/01/2018\n",
       "598    09/30/2018\n",
       "599    09/30/2018\n",
       "600    09/30/2018\n",
       "Name: Date, Length: 601, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=new_tweets,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets=new_tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets['label']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpe24jhwlq\\model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction 1: [1]\n",
      "Prediction 2: [0]\n",
      "Prediction 3: [1]\n",
      "Prediction 4: [1]\n",
      "Prediction 5: [1]\n",
      "Prediction 6: [0]\n",
      "Prediction 7: [1]\n",
      "Prediction 8: [1]\n",
      "Prediction 9: [0]\n",
      "Prediction 10: [0]\n",
      "Prediction 11: [1]\n",
      "Prediction 12: [1]\n",
      "Prediction 13: [0]\n",
      "Prediction 14: [0]\n",
      "Prediction 15: [1]\n",
      "Prediction 16: [0]\n",
      "Prediction 17: [1]\n",
      "Prediction 18: [1]\n",
      "Prediction 19: [1]\n",
      "Prediction 20: [1]\n",
      "Prediction 21: [1]\n",
      "Prediction 22: [1]\n",
      "Prediction 23: [1]\n",
      "Prediction 24: [0]\n",
      "Prediction 25: [1]\n",
      "Prediction 26: [1]\n",
      "Prediction 27: [1]\n",
      "Prediction 28: [1]\n",
      "Prediction 29: [1]\n",
      "Prediction 30: [1]\n",
      "Prediction 31: [1]\n",
      "Prediction 32: [1]\n",
      "Prediction 33: [1]\n",
      "Prediction 34: [0]\n",
      "Prediction 35: [1]\n",
      "Prediction 36: [1]\n",
      "Prediction 37: [1]\n",
      "Prediction 38: [0]\n",
      "Prediction 39: [0]\n",
      "Prediction 40: [0]\n",
      "Prediction 41: [0]\n",
      "Prediction 42: [1]\n",
      "Prediction 43: [1]\n",
      "Prediction 44: [0]\n",
      "Prediction 45: [1]\n",
      "Prediction 46: [1]\n",
      "Prediction 47: [1]\n",
      "Prediction 48: [0]\n",
      "Prediction 49: [1]\n",
      "Prediction 50: [1]\n",
      "Prediction 51: [0]\n",
      "Prediction 52: [1]\n",
      "Prediction 53: [1]\n",
      "Prediction 54: [1]\n",
      "Prediction 55: [1]\n",
      "Prediction 56: [1]\n",
      "Prediction 57: [1]\n",
      "Prediction 58: [1]\n",
      "Prediction 59: [1]\n",
      "Prediction 60: [1]\n",
      "Prediction 61: [1]\n",
      "Prediction 62: [1]\n",
      "Prediction 63: [1]\n",
      "Prediction 64: [0]\n",
      "Prediction 65: [1]\n",
      "Prediction 66: [1]\n",
      "Prediction 67: [1]\n",
      "Prediction 68: [1]\n",
      "Prediction 69: [1]\n",
      "Prediction 70: [1]\n",
      "Prediction 71: [0]\n",
      "Prediction 72: [1]\n",
      "Prediction 73: [1]\n",
      "Prediction 74: [0]\n",
      "Prediction 75: [1]\n",
      "Prediction 76: [1]\n",
      "Prediction 77: [1]\n",
      "Prediction 78: [1]\n",
      "Prediction 79: [1]\n",
      "Prediction 80: [1]\n",
      "Prediction 81: [1]\n",
      "Prediction 82: [1]\n",
      "Prediction 83: [1]\n",
      "Prediction 84: [1]\n",
      "Prediction 85: [1]\n",
      "Prediction 86: [1]\n",
      "Prediction 87: [1]\n",
      "Prediction 88: [1]\n",
      "Prediction 89: [1]\n",
      "Prediction 90: [1]\n",
      "Prediction 91: [1]\n",
      "Prediction 92: [1]\n",
      "Prediction 93: [0]\n",
      "Prediction 94: [1]\n",
      "Prediction 95: [1]\n",
      "Prediction 96: [1]\n",
      "Prediction 97: [1]\n",
      "Prediction 98: [1]\n",
      "Prediction 99: [0]\n",
      "Prediction 100: [1]\n",
      "Prediction 101: [1]\n",
      "Prediction 102: [0]\n",
      "Prediction 103: [1]\n",
      "Prediction 104: [0]\n",
      "Prediction 105: [1]\n",
      "Prediction 106: [1]\n",
      "Prediction 107: [1]\n",
      "Prediction 108: [0]\n",
      "Prediction 109: [1]\n",
      "Prediction 110: [0]\n",
      "Prediction 111: [1]\n",
      "Prediction 112: [1]\n",
      "Prediction 113: [1]\n",
      "Prediction 114: [1]\n",
      "Prediction 115: [1]\n",
      "Prediction 116: [1]\n",
      "Prediction 117: [0]\n",
      "Prediction 118: [0]\n",
      "Prediction 119: [0]\n",
      "Prediction 120: [0]\n",
      "Prediction 121: [1]\n",
      "Prediction 122: [1]\n",
      "Prediction 123: [0]\n",
      "Prediction 124: [1]\n",
      "Prediction 125: [1]\n",
      "Prediction 126: [0]\n",
      "Prediction 127: [1]\n",
      "Prediction 128: [1]\n",
      "Prediction 129: [1]\n",
      "Prediction 130: [1]\n",
      "Prediction 131: [1]\n",
      "Prediction 132: [1]\n",
      "Prediction 133: [1]\n",
      "Prediction 134: [1]\n",
      "Prediction 135: [1]\n",
      "Prediction 136: [0]\n",
      "Prediction 137: [1]\n",
      "Prediction 138: [0]\n",
      "Prediction 139: [1]\n",
      "Prediction 140: [1]\n",
      "Prediction 141: [1]\n",
      "Prediction 142: [1]\n",
      "Prediction 143: [1]\n",
      "Prediction 144: [1]\n",
      "Prediction 145: [0]\n",
      "Prediction 146: [0]\n",
      "Prediction 147: [0]\n",
      "Prediction 148: [0]\n",
      "Prediction 149: [0]\n",
      "Prediction 150: [1]\n",
      "Prediction 151: [1]\n",
      "Prediction 152: [1]\n",
      "Prediction 153: [1]\n",
      "Prediction 154: [1]\n",
      "Prediction 155: [1]\n",
      "Prediction 156: [1]\n",
      "Prediction 157: [1]\n",
      "Prediction 158: [1]\n",
      "Prediction 159: [0]\n",
      "Prediction 160: [0]\n",
      "Prediction 161: [1]\n",
      "Prediction 162: [1]\n",
      "Prediction 163: [1]\n",
      "Prediction 164: [1]\n",
      "Prediction 165: [1]\n",
      "Prediction 166: [0]\n",
      "Prediction 167: [1]\n",
      "Prediction 168: [0]\n",
      "Prediction 169: [1]\n",
      "Prediction 170: [1]\n",
      "Prediction 171: [1]\n",
      "Prediction 172: [1]\n",
      "Prediction 173: [0]\n",
      "Prediction 174: [1]\n",
      "Prediction 175: [1]\n",
      "Prediction 176: [1]\n",
      "Prediction 177: [1]\n",
      "Prediction 178: [1]\n",
      "Prediction 179: [1]\n",
      "Prediction 180: [1]\n",
      "Prediction 181: [1]\n",
      "Prediction 182: [1]\n",
      "Prediction 183: [1]\n",
      "Prediction 184: [1]\n",
      "Prediction 185: [0]\n",
      "Prediction 186: [1]\n",
      "Prediction 187: [1]\n",
      "Prediction 188: [1]\n",
      "Prediction 189: [1]\n",
      "Prediction 190: [0]\n",
      "Prediction 191: [1]\n",
      "Prediction 192: [1]\n",
      "Prediction 193: [0]\n",
      "Prediction 194: [0]\n",
      "Prediction 195: [0]\n",
      "Prediction 196: [0]\n",
      "Prediction 197: [0]\n",
      "Prediction 198: [0]\n",
      "Prediction 199: [1]\n",
      "Prediction 200: [1]\n",
      "Prediction 201: [0]\n",
      "Prediction 202: [1]\n",
      "Prediction 203: [1]\n",
      "Prediction 204: [0]\n",
      "Prediction 205: [1]\n",
      "Prediction 206: [1]\n",
      "Prediction 207: [1]\n",
      "Prediction 208: [1]\n",
      "Prediction 209: [1]\n",
      "Prediction 210: [1]\n",
      "Prediction 211: [1]\n",
      "Prediction 212: [1]\n",
      "Prediction 213: [0]\n",
      "Prediction 214: [1]\n",
      "Prediction 215: [0]\n",
      "Prediction 216: [0]\n",
      "Prediction 217: [0]\n",
      "Prediction 218: [0]\n",
      "Prediction 219: [0]\n",
      "Prediction 220: [0]\n",
      "Prediction 221: [1]\n",
      "Prediction 222: [0]\n",
      "Prediction 223: [1]\n",
      "Prediction 224: [1]\n",
      "Prediction 225: [1]\n",
      "Prediction 226: [1]\n",
      "Prediction 227: [1]\n",
      "Prediction 228: [1]\n",
      "Prediction 229: [1]\n",
      "Prediction 230: [1]\n",
      "Prediction 231: [1]\n",
      "Prediction 232: [0]\n",
      "Prediction 233: [0]\n",
      "Prediction 234: [1]\n",
      "Prediction 235: [0]\n",
      "Prediction 236: [1]\n",
      "Prediction 237: [1]\n",
      "Prediction 238: [1]\n",
      "Prediction 239: [1]\n",
      "Prediction 240: [1]\n",
      "Prediction 241: [1]\n",
      "Prediction 242: [1]\n",
      "Prediction 243: [0]\n",
      "Prediction 244: [0]\n",
      "Prediction 245: [0]\n",
      "Prediction 246: [0]\n",
      "Prediction 247: [1]\n",
      "Prediction 248: [0]\n",
      "Prediction 249: [0]\n",
      "Prediction 250: [1]\n",
      "Prediction 251: [1]\n",
      "Prediction 252: [1]\n",
      "Prediction 253: [1]\n",
      "Prediction 254: [0]\n",
      "Prediction 255: [1]\n",
      "Prediction 256: [1]\n",
      "Prediction 257: [0]\n",
      "Prediction 258: [1]\n",
      "Prediction 259: [1]\n",
      "Prediction 260: [0]\n",
      "Prediction 261: [1]\n",
      "Prediction 262: [0]\n",
      "Prediction 263: [1]\n",
      "Prediction 264: [0]\n",
      "Prediction 265: [1]\n",
      "Prediction 266: [1]\n",
      "Prediction 267: [1]\n",
      "Prediction 268: [0]\n",
      "Prediction 269: [0]\n",
      "Prediction 270: [0]\n",
      "Prediction 271: [1]\n",
      "Prediction 272: [0]\n",
      "Prediction 273: [1]\n",
      "Prediction 274: [1]\n",
      "Prediction 275: [1]\n",
      "Prediction 276: [1]\n",
      "Prediction 277: [1]\n",
      "Prediction 278: [1]\n",
      "Prediction 279: [1]\n",
      "Prediction 280: [1]\n",
      "Prediction 281: [1]\n",
      "Prediction 282: [1]\n",
      "Prediction 283: [1]\n",
      "Prediction 284: [1]\n",
      "Prediction 285: [1]\n",
      "Prediction 286: [1]\n",
      "Prediction 287: [1]\n",
      "Prediction 288: [1]\n",
      "Prediction 289: [1]\n",
      "Prediction 290: [1]\n",
      "Prediction 291: [1]\n",
      "Prediction 292: [1]\n",
      "Prediction 293: [1]\n",
      "Prediction 294: [1]\n",
      "Prediction 295: [1]\n",
      "Prediction 296: [1]\n",
      "Prediction 297: [1]\n",
      "Prediction 298: [1]\n",
      "Prediction 299: [1]\n",
      "Prediction 300: [1]\n",
      "Prediction 301: [1]\n",
      "Prediction 302: [1]\n",
      "Prediction 303: [1]\n",
      "Prediction 304: [1]\n",
      "Prediction 305: [1]\n",
      "Prediction 306: [0]\n",
      "Prediction 307: [1]\n",
      "Prediction 308: [1]\n",
      "Prediction 309: [1]\n",
      "Prediction 310: [0]\n",
      "Prediction 311: [0]\n",
      "Prediction 312: [1]\n",
      "Prediction 313: [0]\n",
      "Prediction 314: [0]\n",
      "Prediction 315: [0]\n",
      "Prediction 316: [1]\n",
      "Prediction 317: [1]\n",
      "Prediction 318: [0]\n",
      "Prediction 319: [0]\n",
      "Prediction 320: [0]\n",
      "Prediction 321: [0]\n",
      "Prediction 322: [1]\n",
      "Prediction 323: [1]\n",
      "Prediction 324: [1]\n",
      "Prediction 325: [1]\n",
      "Prediction 326: [0]\n",
      "Prediction 327: [0]\n",
      "Prediction 328: [1]\n",
      "Prediction 329: [1]\n",
      "Prediction 330: [0]\n",
      "Prediction 331: [1]\n",
      "Prediction 332: [1]\n",
      "Prediction 333: [1]\n",
      "Prediction 334: [1]\n",
      "Prediction 335: [1]\n",
      "Prediction 336: [1]\n",
      "Prediction 337: [0]\n",
      "Prediction 338: [1]\n",
      "Prediction 339: [0]\n",
      "Prediction 340: [0]\n",
      "Prediction 341: [1]\n",
      "Prediction 342: [1]\n",
      "Prediction 343: [1]\n",
      "Prediction 344: [1]\n",
      "Prediction 345: [1]\n",
      "Prediction 346: [1]\n",
      "Prediction 347: [0]\n",
      "Prediction 348: [0]\n",
      "Prediction 349: [1]\n",
      "Prediction 350: [1]\n",
      "Prediction 351: [1]\n",
      "Prediction 352: [0]\n",
      "Prediction 353: [1]\n",
      "Prediction 354: [1]\n",
      "Prediction 355: [0]\n",
      "Prediction 356: [0]\n",
      "Prediction 357: [0]\n",
      "Prediction 358: [1]\n",
      "Prediction 359: [0]\n",
      "Prediction 360: [1]\n",
      "Prediction 361: [1]\n",
      "Prediction 362: [0]\n",
      "Prediction 363: [1]\n",
      "Prediction 364: [0]\n",
      "Prediction 365: [1]\n",
      "Prediction 366: [0]\n",
      "Prediction 367: [1]\n",
      "Prediction 368: [1]\n",
      "Prediction 369: [0]\n",
      "Prediction 370: [1]\n",
      "Prediction 371: [1]\n",
      "Prediction 372: [0]\n",
      "Prediction 373: [0]\n",
      "Prediction 374: [0]\n",
      "Prediction 375: [0]\n",
      "Prediction 376: [0]\n",
      "Prediction 377: [0]\n",
      "Prediction 378: [1]\n",
      "Prediction 379: [1]\n",
      "Prediction 380: [0]\n",
      "Prediction 381: [1]\n",
      "Prediction 382: [1]\n",
      "Prediction 383: [0]\n",
      "Prediction 384: [1]\n",
      "Prediction 385: [1]\n",
      "Prediction 386: [1]\n",
      "Prediction 387: [0]\n",
      "Prediction 388: [1]\n",
      "Prediction 389: [1]\n",
      "Prediction 390: [0]\n",
      "Prediction 391: [0]\n",
      "Prediction 392: [0]\n",
      "Prediction 393: [0]\n",
      "Prediction 394: [0]\n",
      "Prediction 395: [1]\n",
      "Prediction 396: [1]\n",
      "Prediction 397: [1]\n",
      "Prediction 398: [0]\n",
      "Prediction 399: [0]\n",
      "Prediction 400: [1]\n",
      "Prediction 401: [1]\n",
      "Prediction 402: [0]\n",
      "Prediction 403: [0]\n",
      "Prediction 404: [0]\n",
      "Prediction 405: [0]\n",
      "Prediction 406: [0]\n",
      "Prediction 407: [0]\n",
      "Prediction 408: [1]\n",
      "Prediction 409: [1]\n",
      "Prediction 410: [1]\n",
      "Prediction 411: [1]\n",
      "Prediction 412: [0]\n",
      "Prediction 413: [1]\n",
      "Prediction 414: [0]\n",
      "Prediction 415: [1]\n",
      "Prediction 416: [1]\n",
      "Prediction 417: [1]\n",
      "Prediction 418: [0]\n",
      "Prediction 419: [0]\n",
      "Prediction 420: [1]\n",
      "Prediction 421: [1]\n",
      "Prediction 422: [0]\n",
      "Prediction 423: [0]\n",
      "Prediction 424: [1]\n",
      "Prediction 425: [0]\n",
      "Prediction 426: [1]\n",
      "Prediction 427: [0]\n",
      "Prediction 428: [1]\n",
      "Prediction 429: [0]\n",
      "Prediction 430: [1]\n",
      "Prediction 431: [1]\n",
      "Prediction 432: [0]\n",
      "Prediction 433: [1]\n",
      "Prediction 434: [1]\n",
      "Prediction 435: [1]\n",
      "Prediction 436: [1]\n",
      "Prediction 437: [0]\n",
      "Prediction 438: [0]\n",
      "Prediction 439: [1]\n",
      "Prediction 440: [1]\n",
      "Prediction 441: [1]\n",
      "Prediction 442: [1]\n",
      "Prediction 443: [1]\n",
      "Prediction 444: [0]\n",
      "Prediction 445: [1]\n",
      "Prediction 446: [0]\n",
      "Prediction 447: [1]\n",
      "Prediction 448: [1]\n",
      "Prediction 449: [0]\n",
      "Prediction 450: [1]\n",
      "Prediction 451: [0]\n",
      "Prediction 452: [1]\n",
      "Prediction 453: [1]\n",
      "Prediction 454: [1]\n",
      "Prediction 455: [1]\n",
      "Prediction 456: [1]\n",
      "Prediction 457: [1]\n",
      "Prediction 458: [0]\n",
      "Prediction 459: [1]\n",
      "Prediction 460: [0]\n",
      "Prediction 461: [0]\n",
      "Prediction 462: [1]\n",
      "Prediction 463: [0]\n",
      "Prediction 464: [0]\n",
      "Prediction 465: [1]\n",
      "Prediction 466: [0]\n",
      "Prediction 467: [1]\n",
      "Prediction 468: [0]\n",
      "Prediction 469: [1]\n",
      "Prediction 470: [0]\n",
      "Prediction 471: [0]\n",
      "Prediction 472: [0]\n",
      "Prediction 473: [1]\n",
      "Prediction 474: [1]\n",
      "Prediction 475: [0]\n",
      "Prediction 476: [1]\n",
      "Prediction 477: [1]\n",
      "Prediction 478: [1]\n",
      "Prediction 479: [0]\n",
      "Prediction 480: [1]\n",
      "Prediction 481: [0]\n",
      "Prediction 482: [1]\n",
      "Prediction 483: [1]\n",
      "Prediction 484: [1]\n",
      "Prediction 485: [0]\n",
      "Prediction 486: [1]\n",
      "Prediction 487: [0]\n",
      "Prediction 488: [0]\n",
      "Prediction 489: [1]\n",
      "Prediction 490: [0]\n",
      "Prediction 491: [0]\n",
      "Prediction 492: [0]\n",
      "Prediction 493: [0]\n",
      "Prediction 494: [0]\n",
      "Prediction 495: [0]\n",
      "Prediction 496: [0]\n",
      "Prediction 497: [1]\n",
      "Prediction 498: [0]\n",
      "Prediction 499: [0]\n",
      "Prediction 500: [0]\n",
      "Prediction 501: [0]\n",
      "Prediction 502: [0]\n",
      "Prediction 503: [0]\n",
      "Prediction 504: [0]\n",
      "Prediction 505: [0]\n",
      "Prediction 506: [0]\n",
      "Prediction 507: [1]\n",
      "Prediction 508: [1]\n",
      "Prediction 509: [0]\n",
      "Prediction 510: [0]\n",
      "Prediction 511: [0]\n",
      "Prediction 512: [0]\n",
      "Prediction 513: [0]\n",
      "Prediction 514: [0]\n",
      "Prediction 515: [1]\n",
      "Prediction 516: [0]\n",
      "Prediction 517: [0]\n",
      "Prediction 518: [0]\n",
      "Prediction 519: [0]\n",
      "Prediction 520: [1]\n",
      "Prediction 521: [1]\n",
      "Prediction 522: [0]\n",
      "Prediction 523: [0]\n",
      "Prediction 524: [1]\n",
      "Prediction 525: [0]\n",
      "Prediction 526: [0]\n",
      "Prediction 527: [0]\n",
      "Prediction 528: [1]\n",
      "Prediction 529: [1]\n",
      "Prediction 530: [0]\n",
      "Prediction 531: [0]\n",
      "Prediction 532: [1]\n",
      "Prediction 533: [1]\n",
      "Prediction 534: [1]\n",
      "Prediction 535: [1]\n",
      "Prediction 536: [1]\n",
      "Prediction 537: [1]\n",
      "Prediction 538: [0]\n",
      "Prediction 539: [1]\n",
      "Prediction 540: [1]\n",
      "Prediction 541: [0]\n",
      "Prediction 542: [1]\n",
      "Prediction 543: [0]\n",
      "Prediction 544: [0]\n",
      "Prediction 545: [0]\n",
      "Prediction 546: [0]\n",
      "Prediction 547: [1]\n",
      "Prediction 548: [1]\n",
      "Prediction 549: [0]\n",
      "Prediction 550: [1]\n",
      "Prediction 551: [1]\n",
      "Prediction 552: [0]\n",
      "Prediction 553: [0]\n",
      "Prediction 554: [1]\n",
      "Prediction 555: [0]\n",
      "Prediction 556: [0]\n",
      "Prediction 557: [1]\n",
      "Prediction 558: [0]\n",
      "Prediction 559: [1]\n",
      "Prediction 560: [1]\n",
      "Prediction 561: [1]\n",
      "Prediction 562: [0]\n",
      "Prediction 563: [1]\n",
      "Prediction 564: [0]\n",
      "Prediction 565: [1]\n",
      "Prediction 566: [0]\n",
      "Prediction 567: [0]\n",
      "Prediction 568: [0]\n",
      "Prediction 569: [1]\n",
      "Prediction 570: [0]\n",
      "Prediction 571: [1]\n",
      "Prediction 572: [0]\n",
      "Prediction 573: [0]\n",
      "Prediction 574: [0]\n",
      "Prediction 575: [0]\n",
      "Prediction 576: [0]\n",
      "Prediction 577: [0]\n",
      "Prediction 578: [1]\n",
      "Prediction 579: [1]\n",
      "Prediction 580: [1]\n",
      "Prediction 581: [1]\n",
      "Prediction 582: [1]\n",
      "Prediction 583: [1]\n"
     ]
    }
   ],
   "source": [
    "predictions = estimator.predict(input_fn=predict_input_fn)\n",
    "for i, p in enumerate(predictions):\n",
    "  print(\"Prediction %s: %s\" % (i + 1, p['class_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred=[]\n",
    "for i, p in enumerate(predictions):\n",
    "   new_pred.append(p['class_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>signed one important largest trade deals u wor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usmca</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightly looked building somewhere russia put z...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh get good developer happily living life see ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrived argentina busy two days planned import...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alan dershowitz crimes mueller authority rovin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>demonstrates robert mueller partisans evidence...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>landed argentina melania g summit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rnc chair ronna mcdaniel oversaw history defyi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>working hard going get better</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new books coming forget two great originals wr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>new book spygate attempted sabotage donald j t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>really done great job capturing long held view...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arthur laffer two talented men completed incre...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>written absolutely fascinating book back game ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>argentina president vladimir putin look forwar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>based fact ships sailors returned ukraine russ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>billions dollars pouring coffers u tariffs cha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>illegal joseph mccarthy style witch hunt one s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ever see investigation search crime time muell...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>general motors counter auto companies big stee...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>much happening discredited witch hunt total ho...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sebastian gorka talented man got know well wor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>behalf melania entire trump family want wish m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>steel dynamics announced build brand new milli...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>g would closing plants ohio michigan maryland ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reason small truck business u go favorite many...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>disgusting fake news everything within power r...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>congratulations senator cindy hyde smith big w...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>brenda snipes charge voting broward county flo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>see time go rallies order help great republica...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>mexico canada united states great partnership ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>blowout numbers new jobs separately services m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>thank congressman tom reed new york wonderful ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>thank governor phil bryant great honor maga</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>stock market reached time high administration ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>failing new york times something never seen do...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>congressman texas true fighter patriot highly ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>thank mississippi together making america great</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>today administration provided historic levels ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>national wage growth highest nearly months acc...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>god bless u maga</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>thank mississippi love</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>really incredible time nation respected</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>usmca wins praise victory american industries ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>proud great first lady loves</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>yesterday great honor present medal honor rona...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>reason vote democrat tired winning</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>great reviews new usmca thank mexico canada wo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>happy th birthday tristan special member trump...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>wow thank tennessee</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>thank tennessee love</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>news conference usmca morning rose garden whit...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>congratulations mexico canada</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>deficiencies mistakes nafta greatly opens mark...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>deficiencies mistakes nafta greatly opens mark...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>late last night deadline reached wonderful new...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>wow starting hear democrats thinking obstruct ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>african american unemployment lowest number hi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>like many watch saturday night live even thoug...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text label\n",
       "0    signed one important largest trade deals u wor...      \n",
       "1                                                usmca      \n",
       "2    lightly looked building somewhere russia put z...      \n",
       "3    oh get good developer happily living life see ...      \n",
       "4    arrived argentina busy two days planned import...      \n",
       "5    alan dershowitz crimes mueller authority rovin...      \n",
       "6    demonstrates robert mueller partisans evidence...      \n",
       "7                    landed argentina melania g summit      \n",
       "8    rnc chair ronna mcdaniel oversaw history defyi...      \n",
       "9                        working hard going get better      \n",
       "10   new books coming forget two great originals wr...      \n",
       "11   new book spygate attempted sabotage donald j t...      \n",
       "12   really done great job capturing long held view...      \n",
       "13   arthur laffer two talented men completed incre...      \n",
       "14   written absolutely fascinating book back game ...      \n",
       "15   argentina president vladimir putin look forwar...      \n",
       "16   based fact ships sailors returned ukraine russ...      \n",
       "17   billions dollars pouring coffers u tariffs cha...      \n",
       "18   illegal joseph mccarthy style witch hunt one s...      \n",
       "19   ever see investigation search crime time muell...      \n",
       "20   general motors counter auto companies big stee...      \n",
       "21   much happening discredited witch hunt total ho...      \n",
       "22   sebastian gorka talented man got know well wor...      \n",
       "23   behalf melania entire trump family want wish m...      \n",
       "24   steel dynamics announced build brand new milli...      \n",
       "25   g would closing plants ohio michigan maryland ...      \n",
       "26   reason small truck business u go favorite many...      \n",
       "27   disgusting fake news everything within power r...      \n",
       "28   congratulations senator cindy hyde smith big w...      \n",
       "29   brenda snipes charge voting broward county flo...      \n",
       "..                                                 ...   ...\n",
       "569  see time go rallies order help great republica...      \n",
       "570  mexico canada united states great partnership ...      \n",
       "571  blowout numbers new jobs separately services m...      \n",
       "572  thank congressman tom reed new york wonderful ...      \n",
       "573        thank governor phil bryant great honor maga      \n",
       "575  stock market reached time high administration ...      \n",
       "576  failing new york times something never seen do...      \n",
       "577  congressman texas true fighter patriot highly ...      \n",
       "578    thank mississippi together making america great      \n",
       "579  today administration provided historic levels ...      \n",
       "580  national wage growth highest nearly months acc...      \n",
       "581                                   god bless u maga      \n",
       "582                             thank mississippi love      \n",
       "583            really incredible time nation respected      \n",
       "584  usmca wins praise victory american industries ...      \n",
       "585                       proud great first lady loves      \n",
       "586  yesterday great honor present medal honor rona...      \n",
       "587                 reason vote democrat tired winning      \n",
       "588  great reviews new usmca thank mexico canada wo...      \n",
       "589  happy th birthday tristan special member trump...      \n",
       "590                                wow thank tennessee      \n",
       "591                               thank tennessee love      \n",
       "593  news conference usmca morning rose garden whit...      \n",
       "594                      congratulations mexico canada      \n",
       "595  deficiencies mistakes nafta greatly opens mark...      \n",
       "596  deficiencies mistakes nafta greatly opens mark...      \n",
       "597  late last night deadline reached wonderful new...      \n",
       "598  wow starting hear democrats thinking obstruct ...      \n",
       "599  african american unemployment lowest number hi...      \n",
       "600  like many watch saturday night live even thoug...      \n",
       "\n",
       "[583 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=get_predictions(estimator, predict_test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = pd.DataFrame({'text':test['text'],'actual':test['new_label'],'predicted': predicted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdef = tf.GraphDef()\n",
    "from google.protobuf import text_format\n",
    "text_format.Merge(open(\"./output/graph.pbtxt\").read(), gdef)\n",
    "show_graph(gdef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
